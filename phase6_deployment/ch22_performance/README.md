# Chapter 22: FastAPI 성능 최적화

## 학습 목표

1. Gunicorn + Uvicorn 워커 구성의 원리와 최적 설정법을 이해한다
2. 워커 수 계산 공식과 CPU 코어 기반 튜닝 방법을 익힌다
3. 인메모리 캐싱 전략을 구현하여 응답 시간을 단축할 수 있다
4. 프로파일링 도구를 활용하여 병목 지점을 식별할 수 있다
5. 캐시 적용 전후의 성능 차이를 측정하고 분석할 수 있다

---

## 핵심 개념

### 1. Gunicorn + Uvicorn 워커 구성

FastAPI는 비동기(ASGI) 프레임워크이므로 Uvicorn을 서버로 사용한다. 프로덕션 환경에서는 Gunicorn을 프로세스 매니저로 두고 Uvicorn 워커를 여러 개 실행하는 구성이 권장된다.

```
[클라이언트] → [Gunicorn (마스터 프로세스)]
                  ├── Uvicorn 워커 1
                  ├── Uvicorn 워커 2
                  ├── Uvicorn 워커 3
                  └── Uvicorn 워커 4
```

**Gunicorn의 역할:**
- 워커 프로세스의 생성, 관리, 재시작을 담당한다
- 워커가 비정상 종료되면 자동으로 새 워커를 생성한다
- Graceful 재시작으로 무중단 배포를 지원한다

**Uvicorn 워커의 역할:**
- 각 워커가 독립적인 이벤트 루프를 실행한다
- 비동기 요청 처리를 담당한다

### 2. 워커 수 계산

권장 공식:

```
워커 수 = (CPU 코어 수 × 2) + 1
```

| CPU 코어 | 워커 수 | 설명 |
|-----------|---------|------|
| 1 | 3 | 최소 구성 (소규모 서비스) |
| 2 | 5 | 소규모 프로덕션 |
| 4 | 9 | 일반적인 프로덕션 |
| 8 | 17 | 대규모 트래픽 처리 |

> 주의: 워커 수를 무작정 늘리면 메모리 사용량이 증가한다. 각 워커는 독립적인 메모리 공간을 사용하므로, 서버의 가용 메모리를 고려하여 설정해야 한다.

### 3. 캐싱 전략

| 캐싱 방식 | 장점 | 단점 | 적합한 상황 |
|-----------|------|------|-------------|
| **인메모리 (dict)** | 가장 빠름, 구현 간단 | 워커 간 공유 불가, 메모리 제한 | 단일 워커, 소규모 데이터 |
| **TTL 기반 캐시** | 자동 만료, 데이터 신선도 유지 | 구현 복잡도 증가 | API 응답 캐싱 |
| **Redis** | 워커 간 공유, 영속성, TTL 지원 | 네트워크 지연, 별도 서비스 필요 | 다중 워커, 분산 환경 |
| **HTTP 캐시 헤더** | CDN/브라우저 캐시 활용 | 실시간 데이터에 부적합 | 정적 콘텐츠, 변경 빈도 낮은 데이터 |

### 4. 프로파일링 기초

Python 애플리케이션의 병목 지점을 찾기 위한 도구:

- **`time` 미들웨어**: 각 요청의 처리 시간을 헤더로 반환한다
- **`cProfile`**: Python 표준 프로파일러. 함수별 호출 횟수와 소요 시간을 측정한다
- **`py-spy`**: 프로세스에 붙어서 실시간으로 프로파일링하는 샘플링 프로파일러
- **`line_profiler`**: 코드 한 줄 단위로 실행 시간을 측정한다

---

## 코드 실행 방법

### 기본 실행 (개발용)

```bash
# 단일 워커로 실행 (개발용)
uvicorn main:app --reload

# 성능 비교 테스트
# 브라우저 또는 curl로 아래 엔드포인트에 접속한다
curl http://localhost:8000/slow         # 캐시 없음 (느림)
curl http://localhost:8000/cached       # 캐시 적용 (빠름)
curl http://localhost:8000/stats        # 캐시 통계 확인
```

### Gunicorn으로 실행 (프로덕션)

```bash
# gunicorn 설치
pip install gunicorn

# 설정 파일을 사용하여 실행
gunicorn -c gunicorn.conf.py main:app

# 명령줄 옵션으로 직접 실행
gunicorn main:app \
    --bind 0.0.0.0:8000 \
    --workers 4 \
    --worker-class uvicorn.workers.UvicornWorker \
    --timeout 120
```

### 성능 측정 (벤치마크)

```bash
# Apache Benchmark로 부하 테스트
# 총 1000건의 요청을 동시 10개 연결로 전송한다
ab -n 1000 -c 10 http://localhost:8000/slow
ab -n 1000 -c 10 http://localhost:8000/cached

# hey 도구로 부하 테스트 (더 현대적인 도구)
hey -n 1000 -c 10 http://localhost:8000/slow
hey -n 1000 -c 10 http://localhost:8000/cached
```

---

## 실습 포인트

1. **캐시 효과 비교**: `/slow`와 `/cached` 엔드포인트의 응답 시간을 비교하고, `/stats`에서 캐시 적중률을 확인한다
2. **워커 수 튜닝**: Gunicorn 워커 수를 1, 2, 4, 8로 변경하며 동시 요청 처리량을 측정한다
3. **캐시 만료 실험**: TTL 값을 변경하며 캐시 갱신 주기가 응답 시간에 미치는 영향을 관찰한다
4. **응답 시간 헤더 분석**: `X-Process-Time` 헤더를 통해 서버 처리 시간을 추적한다
5. **프로파일링 실습**: `cProfile`을 사용하여 무거운 연산 함수의 병목 지점을 분석한다

---

## 프로젝트 구조

```
ch22_performance/
├── README.md              # 학습 가이드 (현재 문서)
├── main.py                # FastAPI 애플리케이션 (캐싱 구현 포함)
└── gunicorn.conf.py       # Gunicorn 설정 파일
```
